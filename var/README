
I. Task description
-------------------
This README file describes the data that was released for the NLI (Native
Language Identification) Shared Task 2017.  This shared task will be hosted at
the 12th Workshop on Innovative Use of NLP for Building Educational Applications
at EMNLP 2017 in Copenhagen on September 8, 2017.  Further information about
the workshop is available at the following website:

https://www.cs.rochester.edu/~tetreaul/emnlp-bea12.html#nli

The official site for the NLI Shared Task 2017 is here:

https://sites.google.com/site/nlisharedtask/

NLI Shared Task 2017 consists of the following three sub-tasks:

1) Essay Task: classification of an individaul's native language based on an essay
written in English

2) Speech Task: classification of an individual's native language based on an
English spoken response (transcriptions and i-vectors are provided for the spoken
responses, but not the audio file)

3) Fusion Task: classification of an individual's native language based on a written
essay and a spoken response 

The object of the tasks are to predict the native language of a non-native
speaker of English given an essay and/or speech transcription written/spoken by
that individual in the context of a large-scale standardized assessment of English
proficiency for academic purposes. The following 11 native languages are represented in
the dataset:

Arabic (ARA)
Chinese (CHI)
French (FRE)
German (GER)
Hindi (HIN)
Italian (ITA)
Japanese (JPN)
Korean (KOR)
Spanish (SPA)
Telugu (TEL)
Turkish (TUR)

For the Essay Task (1), there are 11,000 essays (1,000 per L1) in the training
partition (train) and 1,100 (100 per L1) in the development partition (dev).

For the Speech Task (2), there are 11,000 orthographic transcriptions of 45-second
English spoken responses, (1,000 per L1) in the training partition (train) and 1,100
(100 per L1) in the development partition (dev).  In addition, i-vectors computed 
from the 45-second audio file corresponding to each orthographic transcription are 
provided. i-vectors are compact representations of a speech utterance in a low-dimensional 
subspace based upon factor analysis. The dimensions of the i-vectors (800) and number of 
Gaussian components (1024) are tuned on the development set by using the Kaldi toolkit 
(http://kaldi-asr.org).

Since the audio files are not provided for this task, the i-vectors
were included to provide a more realistic sense of the performance of speech-based
NLI system (as shown below, the baseline system for the Speech Task using only the
transcriptions is 0.52, which is much lower than the baseline system for the Speech
Task when the i-vectors are included, i.e., 0.76).

For the Fusion Task (3), a combination of the data from the Essay Task and Speech
Task can be used.

II. Reproducing the baselines
----------------------------
NOTE: Due to being unable to seed liblinear's random number generator from the public C api, 
      results from Scikit-learn's LinearSVC may vary slightly from one run to the next. Please 
      see http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html for details.


The following five baselines are provided for the NLI Shared Task 2017:

essay_baseline                              baseline system for the Essay Task

speech_transcriptions_baseline              baseline system for the Speech Task using only 

speech_transcriptions+ivectors_baseline	    baseline system for the Speech Task using both
                                            the transcriptions and i-vectors

fusion_baseline                             baseline system for the Fusion Task using the
                                            essays, speech transcriptions, and i-vectors

fusion+ivectors_baseline                    baseline system for the Fusion Task using the
                                            essays and transcriptions of the spoken responses

Two baselines (with and without i-vectors) are provided for both the Speech Task and the
Fusion Task.  The i-vectors are included in order to demonstrate the expected baseline
performance for a speech-based NLI system based on audio files.  Since no audio files are
provided for this task, it is not expected that participants will improve upon the
performance of the i-vectors.  From that perspective, participants may choose to exclude
the i-vectors from their submissions to the Speech Task and Fusion Task in order to
more clearly highlight the relative contribution of specific aspects of their systems.

To run the baseline systems with the default settings, navigate to the
'scripts/' directory and run the following command with the baseline script
of interest:

    $ python <baseline_name>.py

The scripts all train a linear support vector classifier using the scikit-learn
library (scikit-learn.org) using unigram features computed from the tokenized
versions of the of the essay data located in 'data/<baseline_name>/train/tokenized'
and evaluates its performance on the dev data in 'data/<baseline_name>/dev/tokenized'.
A confusion matrix and classification report are printed to the console. In
addition, the feature matrix generated for the train and dev data is saved in
svm_light format under 'data/features/<baseline_name>/train' and
'data/features/<baseline_name>/dev' respectively.

script arguments for 'essays_baseline.py' and 'speech_transcriptions_baseline.py':

  --train                      The name of the training partition directories used for 
                               reading training data and labels and writing training 
                               feature files. By default, the baseline script uses 
                               'train'.

  --test                       The name of the test partition directories used for 
                               reading test data and labels and writing dev feature 
                               files. By default, the baseline script uses 'dev'.

  --preprocessor               Name of the directory containing the processed essay 
                               data. This package comes with two options: 'original' 
                               is the unprocessed raw essay text. 'tokenized' is the 
                               sentence-and-word-segmented text. The baseline uses 
                               'tokenized' by default. To add custom preprocessing of 
                               the data, output the processed data to a new directory 
                               under '/data/{essays|speech_transcriptions}/{train|dev}/',
                               and pass the name of that directory to this parameter.

  --training_features          Path to a precomputed feature file for the train 
                               partition, in svm_light format. It must have the 
                               same number of rows, in the same order, as the 
                               corresponding labels files. To avoid dimensionality 
                               mismatch, training_features and test_features files 
                               must be provided together. If only one is provided, 
                               the script will ignore it and re-compute features from 
                               the data.

  --test_features:             Path to a precomputed feature file for the test 
                               partition, in svm_light format. It must have the 
                               same number of rows, in the same order, as the 
                               corresponding labels files. To avoid dimensionality 
                               mismatch, training_features and test_features files 
                               must be provided together. If only one is provided, 
                               the script will ignore it and re-compute features from 
                               the data.

  --feature_outfile_name:      Custom name for feature files generated by script. 
                               The script will prepend the appropriate partition name to 
                               each of the feature files. If no feature_outfile_name is given,
                               the feature files will be named using the date and time.

 --predictions_outfile_name:   Custom name for predictions file (will be saved in
                               ../predictions/essays/). If not provided, the predictions
                               file will be named using the date and time. 

Arguments specific to fusion baselines:

  --essay_training_features           Path to file containing precomputed training features.
                                      None by default. Should be located in
                                      ../data/features/essays/<train_partition_name>/

  --essay_test_features               Path to file containing precomputed test features.
                                      None by default. Should be located in
                                      ../data/features/essays/<test_partition_name>/

  --transcription_training_features   Path to file containing precomputed training features.
                                      None by default. Should be located in ../data/features
                                      /speech_transcriptions/<train_partition_name>/

  --transcription_test_features       Path to file containing precomputed test features.
                                      None by default. Should be located in ../data/features
                                      /speech_transcriptions/<test_partition_name>/

  --combined_training_features        Path to file containing precomputed combined training
                                      features. Should be located in
                                      ../data/features/fusion/<train_partition_name>

  --combined_test_features            Path to file containing precomputed combined test
                                      features. Should be located in
                                      ../data/features/fusion/<test_partition_name>

III. Directory structure
------------------------
    scripts/
        baseline_util.py  # common utility functions contained here.
        essay_baseline.py
        speech_transcriptions_baseline.py
        fusion_baseline.py
        speech_transcriptions+ivectors_baseline.py
        fusion+ivectors_baseline.py

    predictions/
        essays/
        speech_transcriptions/
        fusion/
        speech_transcriptions+ivectors/
        fusion+ivectors/

    data/
        essays/
            train/
                original/  # essays in their original format
                tokenized/  # essays segmented by sentence and token
            dev/
                original/ 
                tokenized/
        speech_transcriptions/
            train/
                original/
                tokenized/
            dev/
                original/
                tokenized/
        features/
            essays/
                train/
                dev/
            speech_transcriptions/
                train/
                dev/
            fusion/
                train/
                dev/
            speech_ivectors
                train/
                dev/
            speech_transcriptions+ivectors
                train/
                dev/
            fusion+ivectors
                train/
                dev/

        labels/
            train/
            dev/



IV. Baseline results (on the development set)
---------------------------------------------

1) Essay Task (essay_baseline):

    Confusion Matrix:
           ARA  CHI  FRE  GER  HIN  ITA  JPN  KOR  SPA  TEL  TUR
      ARA   72    1    1    2    3    5    3    2    5    4    2
      CHI    2   77    1    2    2    0    8    3    1    1    3
      FRE    3    4   73    5    2    5    1    0    4    0    3
      GER    2    3    5   81    1    1    0    2    4    1    0
      HIN    2    0    0    4   67    0    0    1    4   20    2
      ITA    1    2    7    4    0   76    1    0    5    1    3
      JPN    1    4    2    2    0    0   78    6    3    0    4
      KOR    0    8    1    1    0    1   17   65    2    3    2
      SPA    5    1    7    1    1   12    0    6   60    1    6
      TEL    1    1    0    1   17    0    0    0    2   76    2
      TUR    6    5    0    1    0    1    3    3    8    2   71

    Classification Results:
                 precision    recall  f1-score   support

            ARA       0.76      0.72      0.74       100
            CHI       0.73      0.77      0.75       100
            FRE       0.75      0.73      0.74       100
            GER       0.78      0.81      0.79       100
            HIN       0.72      0.67      0.69       100
            ITA       0.75      0.76      0.76       100
            JPN       0.70      0.78      0.74       100
            KOR       0.74      0.65      0.69       100
            SPA       0.61      0.60      0.61       100
            TEL       0.70      0.76      0.73       100
            TUR       0.72      0.71      0.72       100

    avg / total       0.72      0.72      0.72      1100

2) Speech Task

2.a) speech_transcriptions_baseline

    Confusion matrix:   
           ARA  CHI  FRE  GER  HIN  ITA  JPN  KOR  SPA  TEL  TUR
      ARA   29    8    9    5    7    5    6    6    7    8   10
      CHI    3   53    2    4    6    2    5   10    6    2    7
      FRE    2    2   45    6    3   12    4    3   11    3    9
      GER    5    5    4   66    3    1    2    2    8    0    4
      HIN    3    2    0    4   56    1    1    2    6   21    4
      ITA    3    2    7    6    5   65    1    1    6    2    2
      JPN    6   10    3    1    2    6   58    3    3    3    5
      KOR    5   10    3    2    3    4   13   54    3    2    1
      SPA    5    3    7    6    5   18    2    4   43    2    5
      TEL    7    0    2    3   28    1    1    1    3   48    6
      TUR    4    4    5    4    1   12    2    3    6    3   56

    Classification Results:
                 precision    recall  f1-score   support

            ARA       0.40      0.29      0.34       100
            CHI       0.54      0.53      0.53       100
            FRE       0.52      0.45      0.48       100
            GER       0.62      0.66      0.64       100
            HIN       0.47      0.56      0.51       100
            ITA       0.51      0.65      0.57       100
            JPN       0.61      0.58      0.59       100
            KOR       0.61      0.54      0.57       100
            SPA       0.42      0.43      0.43       100
            TEL       0.51      0.48      0.49       100
            TUR       0.51      0.56      0.54       100

    avg / total       0.52      0.52      0.52      1100

2.b) speech_transcriptions+ivectors_baseline

    Confusion Matrix:
           ARA  CHI  FRE  GER  HIN  ITA  JPN  KOR  SPA  TEL  TUR
      ARA   74    0    4    0    4    5    2    5    1    0    5
      CHI    3   74    3    4    2    0    4    8    2    0    0
      FRE    2    1   71    5    1    3    3    2   10    1    1
      GER    0    1    3   87    2    2    1    0    4    0    0
      HIN    0    1    1    0   73    0    1    1    3   20    0
      ITA    1    0    5    0    1   82    1    3    7    0    0
      JPN    0    2    1    1    0    1   88    4    3    0    0
      KOR    2    3    2    1    2    0   12   75    3    0    0
      SPA    6    1    9    0    3    6    3    3   67    2    0
      TEL    1    0    0    0   30    1    2    0    3   63    0
      TUR    4    1    4    2    5    1    4    2    0    0   77

    Classification Results:
                 precision    recall  f1-score   support
  
            ARA       0.80      0.74      0.77       100
            CHI       0.88      0.74      0.80       100
            FRE       0.69      0.71      0.70       100
            GER       0.87      0.87      0.87       100
            HIN       0.59      0.73      0.65       100
            ITA       0.81      0.82      0.82       100
            JPN       0.73      0.88      0.80       100
            KOR       0.73      0.75      0.74       100
            SPA       0.65      0.67      0.66       100
            TEL       0.73      0.63      0.68       100
            TUR       0.93      0.77      0.84       100

    avg / total       0.76      0.76      0.76      1100  

3) Fusion Task

3.a) fusion_baseline

    Confusion Matrix:
           ARA  CHI  FRE  GER  HIN  ITA  JPN  KOR  SPA  TEL  TUR
      ARA   70    1    3    1    6    3    0    1    9    5    1
      CHI    2   77    1    2    3    0    4    6    1    1    3
      FRE    2    4   75    4    2    7    0    0    2    1    3
      GER    1    0    2   86    1    1    0    1    8    0    0
      HIN    1    0    0    4   70    2    0    0    3   18    2
      ITA    1    0    4    5    1   79    0    1    6    0    3
      JPN    1    7    1    3    0    2   79    5    2    0    0
      KOR    1    6    3    0    1    0   14   72    1    2    0
      SPA    5    1    7    1    2   13    0    1   65    0    5
      TEL    2    1    0    0   20    0    1    0    1   73    2
      TUR    6    2    2    2    1    2    2    1    3    1   78

    Classification Results:
                 precision    recall  f1-score   support

            ARA       0.76      0.70      0.73       100
            CHI       0.78      0.77      0.77       100
            FRE       0.77      0.75      0.76       100
            GER       0.80      0.86      0.83       100
            HIN       0.65      0.70      0.68       100
            ITA       0.72      0.79      0.76       100
            JPN       0.79      0.79      0.79       100
            KOR       0.82      0.72      0.77       100
            SPA       0.64      0.65      0.65       100
            TEL       0.72      0.73      0.73       100
            TUR       0.80      0.78      0.79       100

    avg / total       0.75      0.75      0.75      1100

3.b) fusion+ivectors_baseline

    Confusion Matrix:
           ARA  CHI  FRE  GER  HIN  ITA  JPN  KOR  SPA  TEL  TUR
      ARA   75    0    5    1    4    3    5    1    3    0    3
      CHI    3   80    1    3    0    0    2    5    5    1    0
      FRE    3    0   76    6    1    5    2    0    6    0    1
      GER    0    2    2   89    0    1    0    0    5    0    1
      HIN    2    1    0    0   67    1    0    2    4   22    1
      ITA    0    0    3    2    0   88    1    2    3    0    1
      JPN    0    1    3    1    0    0   92    2    0    1    0
      KOR    2    3    1    0    0    1   11   79    3    0    0
      SPA    6    3    9    2    3    7    3    2   63    0    2
      TEL    1    0    0    0   23    1    2    0    2   71    0
      TUR    4    2    2    2    0    2    3    2    2    0   81

    Classification Results:
                 precision    recall  f1-score   support

            ARA       0.78      0.75      0.77       100
            CHI       0.87      0.80      0.83       100
            FRE       0.75      0.76      0.75       100
            GER       0.84      0.89      0.86       100
            HIN       0.68      0.67      0.68       100
            ITA       0.81      0.88      0.84       100
            JPN       0.76      0.92      0.83       100
            KOR       0.83      0.79      0.81       100
            SPA       0.66      0.63      0.64       100
            TEL       0.75      0.71      0.73       100
            TUR       0.90      0.81      0.85       100

    avg / total       0.78      0.78      0.78      1100

